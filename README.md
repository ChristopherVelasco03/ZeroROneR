# üç∫ Clasificadores Zero-R y One-R

[![Python](https://img.shields.io/badge/Python-3.7%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Pandas](https://img.shields.io/badge/Pandas-Required-orange.svg)](https://pandas.pydata.org/)

Implementaci√≥n educativa de algoritmos fundamentales de clasificaci√≥n supervisada para an√°lisis de datos y aprendizaje autom√°tico.

---

## üìã Tabla de Contenidos

- [Descripci√≥n](#-descripci√≥n)
- [Caracter√≠sticas](#-caracter√≠sticas)
- [Requisitos](#-requisitos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso R√°pido](#-uso-r√°pido)
- [Documentaci√≥n Detallada](#-documentaci√≥n-detallada)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Ejemplo de Salida](#-ejemplo-de-salida)
- [Algoritmos Implementados](#-algoritmos-implementados)

---

## üéØ Descripci√≥n

Esta librer√≠a implementa dos algoritmos cl√°sicos de clasificaci√≥n que sirven como l√≠nea base (baseline) en proyectos de aprendizaje autom√°tico:

### **Zero-R (Regla Cero)**
Clasificador que predice siempre la clase m√°s frecuente en el conjunto de entrenamiento. Aunque simple, establece el rendimiento m√≠nimo que cualquier modelo inteligente debe superar.

### **One-R (Una Regla)**
Algoritmo que selecciona el atributo individual m√°s predictivo y genera reglas de clasificaci√≥n basadas en sus valores. A pesar de su simplicidad, puede lograr alta precisi√≥n en ciertos problemas.

**Caso de Uso:** An√°lisis de preferencias de cervezas basado en caracter√≠sticas demogr√°ficas y contextuales.

---

## ‚ú® Caracter√≠sticas

- ‚úÖ **Carga Inteligente de Datos**: Soporte para CSV y tablas Markdown con auto-detecci√≥n de formato
- ‚úÖ **Arquitectura Orientada a Objetos**: Dise√±o modular con clases base abstractas
- ‚úÖ **Evaluaci√≥n Robusta**: Sistema de validaci√≥n iterativa con m√∫ltiples particiones train/test
- ‚úÖ **An√°lisis Estad√≠stico**: C√°lculo de precisi√≥n promedio y desviaci√≥n est√°ndar
- ‚úÖ **Comparaci√≥n Autom√°tica**: Framework para comparar rendimiento entre modelos
- ‚úÖ **Reproducibilidad**: Control de semillas aleatorias para experimentos replicables
- ‚úÖ **Interfaz Interactiva**: Entrada de par√°metros por consola para experimentaci√≥n
- ‚úÖ **Visualizaci√≥n de Reglas**: Inspecci√≥n de las reglas generadas por One-R

---

## üîß Requisitos

```
Python >= 3.7
pandas >= 1.0.0
numpy >= 1.18.0
```

**Nota:** Las librer√≠as `collections` y `abc` son parte de la biblioteca est√°ndar de Python.

---

## üì• Instalaci√≥n

### Opci√≥n 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/cervezas-zeror-oner.git
cd cervezas-zeror-oner
```

### Opci√≥n 2: Descargar ZIP

Descarga el archivo ZIP desde GitHub y extr√°elo en tu directorio de trabajo.

### Instalar Dependencias

```bash
pip install pandas numpy
```

O usando requirements.txt (si lo creas):

```bash
pip install -r requirements.txt
```

---

## üöÄ Uso R√°pido

### Ejecuci√≥n B√°sica

```bash
python cervezas.py
```

El programa te solicitar√°:
- **N√∫mero de iteraciones** para evaluaci√≥n (ej: 10)
- **Porcentaje de datos** para entrenamiento (ej: 0.7 para 70%)

### Ejemplo de Interacci√≥n

```
Ingrese el n√∫mero de iteraciones para evaluaci√≥n (ej: 10): 10
Ingrese el porcentaje de datos para entrenamiento (ej: 0.7): 0.7
```

---

## üìñ Documentaci√≥n Detallada

### M√≥dulos Principales

#### 1Ô∏è‚É£ **M√≥dulo de Carga de Datos**

```python
from cervezas import cargar_datos, dividir_datos

# Cargar datos
datos = cargar_datos('cervezas.txt')

# Preparar caracter√≠sticas y objetivo
X = datos.drop('Prefiere', axis=1)
y = datos['Prefiere']

# Dividir datos
X_train, X_test, y_train, y_test = dividir_datos(X, y, porcentaje_entrenamiento=0.7, semilla=42)
```

#### 2Ô∏è‚É£ **M√≥dulo de Modelos**

##### Zero-R

```python
from cervezas import ZeroR

# Crear y entrenar modelo
modelo_zeror = ZeroR()
modelo_zeror.entrenar(X_train, y_train)

# Realizar predicciones
predicciones = modelo_zeror.predecir(X_test)

# Evaluar
precision = modelo_zeror.evaluar(X_test, y_test)
print(f"Precisi√≥n: {precision:.2%}")
```

##### One-R

```python
from cervezas import OneR

# Crear y entrenar modelo
modelo_oner = OneR()
modelo_oner.entrenar(X_train, y_train)

# Realizar predicciones
predicciones = modelo_oner.predecir(X_test)

# Obtener reglas
reglas = modelo_oner.obtener_reglas()
print(f"Atributo seleccionado: {reglas['atributo']}")
print(f"Reglas: {reglas['reglas']}")
```

#### 3Ô∏è‚É£ **M√≥dulo de Evaluaci√≥n**

```python
from cervezas import Evaluador

# Evaluaci√≥n iterativa
resultados = Evaluador.evaluar_modelo_iterativo(
    modelo_clase=OneR,
    X=X,
    y=y,
    num_iteraciones=10,
    porcentaje_entrenamiento=0.7,
    semilla_base=42
)

# Comparar modelos
comparacion = Evaluador.comparar_modelos({
    'Zero-R': resultados_zeror,
    'One-R': resultados_oner
})
```

---

## üìÅ Estructura del Proyecto

```
Cervezas_ZeroRule_OneRule/
‚îÇ
‚îú‚îÄ‚îÄ cervezas.py          # C√≥digo principal con todos los m√≥dulos
‚îú‚îÄ‚îÄ cervezas.txt         # Dataset de ejemplo (preferencias de cervezas)
‚îú‚îÄ‚îÄ README.md            # Este archivo
‚îî‚îÄ‚îÄ __pycache__/         # Archivos compilados de Python
```

---

## üìä Ejemplo de Salida

```
======================================================================
 LIBRER√çA DE CLASIFICACI√ìN ZERO-R Y ONE-R
======================================================================

[PASO 1] Cargando datos...
‚úì Datos cargados: 20 instancias, 8 columnas
  Columnas: ['G√©nero', 'Edad', 'Ocupaci√≥n', 'Estudiante', 'Situaci√≥n_Sentimental', 
             'Clima', 'M√∫sica', 'Prefiere']

[PASO 2] Preparando datos...
‚úì Caracter√≠sticas: ['G√©nero', 'Edad', 'Ocupaci√≥n', 'Estudiante', 
                    'Situaci√≥n_Sentimental', 'Clima', 'M√∫sica']
‚úì Variable objetivo: 'Prefiere'
‚úì Distribuci√≥n de clases: {'Clara': 13, 'Oscura': 7}

======================================================================
RESULTADOS DEL MODELO: Zero-R
======================================================================

Iteraciones realizadas: 10

Resultados por iteraci√≥n:
Iter   Precisi√≥n Train    Precisi√≥n Test    
---------------------------------------------
1      0.6429             0.6667            
2      0.6429             0.6667            
...

Estad√≠sticas Finales:
  Precisi√≥n promedio (entrenamiento): 0.6429
  Precisi√≥n promedio (prueba):        0.6667
  Desviaci√≥n est√°ndar (prueba):       0.0000

======================================================================
RESULTADOS DEL MODELO: One-R
======================================================================

Iteraciones realizadas: 10

Resultados por iteraci√≥n:
Iter   Precisi√≥n Train    Precisi√≥n Test    
---------------------------------------------
1      0.8571             0.8333            
2      0.8571             0.8333            
...

Estad√≠sticas Finales:
  Precisi√≥n promedio (entrenamiento): 0.8571
  Precisi√≥n promedio (prueba):        0.8333
  Desviaci√≥n est√°ndar (prueba):       0.0000

[Ejemplo de Reglas One-R - √öltima iteraci√≥n]
  Atributo seleccionado: 'Clima'
  Reglas generadas: 3 reglas
    Si Clima = Soleado ‚Üí Clase = Clara
    Si Clima = Nublado ‚Üí Clase = Clara
    Si Clima = Lluvia ‚Üí Clase = Oscura

======================================================================
 COMPARACI√ìN FINAL
======================================================================

Modelo          Precisi√≥n Promedio   Desviaci√≥n     
--------------------------------------------------
Zero-R          0.6667               0.0000         
One-R           0.8333               0.0000         

CONCLUSI√ìN:
  ‚Üí El modelo One-R tiene mejor rendimiento
  ‚Üí Diferencia en precisi√≥n: 0.1667 (16.67%)

======================================================================
 EVALUACI√ìN COMPLETADA
======================================================================
```

---

## üßÆ Algoritmos Implementados

### Zero-R (ZR)

**Principio:** Predecir la clase mayoritaria.

**Ventajas:**
- Extremadamente simple y r√°pido
- No requiere caracter√≠sticas
- Establece baseline m√≠nimo

**Desventajas:**
- No aprende patrones
- Ignora todas las caracter√≠sticas
- Bajo rendimiento en datasets balanceados

**Complejidad Temporal:** $O(n)$ donde $n$ es el n√∫mero de instancias

---

### One-R (1R)

**Principio:** Crear reglas basadas en el mejor atributo individual.

**Algoritmo:**
1. Para cada atributo:
   - Para cada valor del atributo: asignar la clase m√°s frecuente
   - Contar errores de clasificaci√≥n
2. Seleccionar el atributo con menor tasa de error
3. Usar sus reglas para clasificaci√≥n

**Ventajas:**
- Simple e interpretable
- A menudo competitivo con algoritmos complejos
- Genera reglas comprensibles

**Desventajas:**
- Solo usa un atributo
- No captura interacciones entre variables
- Sensible a atributos con muchos valores

**Complejidad Temporal:** $O(m \cdot n)$ donde $m$ = atributos, $n$ = instancias

---

